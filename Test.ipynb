{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 11:26:28.354355: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 11:26:29.292099: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-22 11:26:29.292206: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-22 11:26:29.292217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# save the final model to file\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point, run the test harness\n",
    "#run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 11:26:35.039367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 11:26:35.051493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 11:26:35.053181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 11:26:35.055212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 11:26:35.055733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 11:26:35.057410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 11:26:35.059006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 11:26:35.819575: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 11:26:35.821420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 11:26:35.822923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 11:26:35.824376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13143 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2023-05-22 11:26:37.399727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 72.990\n"
     ]
    }
   ],
   "source": [
    "# evaluate the deep model on the test dataset\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness_load():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 performance: \n",
      "> 74.840\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# See if normalizing the data to have zero mean and standard deviation 1 improves performance\n",
    "\n",
    "def prep_pixels_2(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # calculate mean and standard deviation\n",
    "    train_mean, train_std = train_norm.mean(), train_norm.std()\n",
    "    test_mean, test_std = test_norm.mean(), test_norm.std()\n",
    "    # global standardization of pixels\n",
    "    train_norm = (train_norm - train_mean) / train_std\n",
    "    test_norm = (test_norm - test_mean) / test_std\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness_1task():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_1task.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_1task()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def run_test_harness_load_1task():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_1task.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# entry point, run the test harness\n",
    "print(\"Task 1 performance: \")\n",
    "run_test_harness_load_1task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 Adam performance: \n",
      "> 75.900\n"
     ]
    }
   ],
   "source": [
    "## task 2, Replace the SGD + momentum optimizer with Adam and then AdamW. Do these optimizers lead to better performance and/or faster convergence?\n",
    "import keras.optimizers\n",
    "\n",
    "\n",
    "def define_model_2task(optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(lr=0.001, momentum=0.9)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "\n",
    "def run_test_harness_2task_adam():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_2task('Adam')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_2task_adam.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_2task_adam()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "\n",
    "def run_test_harness_load_2task_adam():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_2task_adam.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# entry point, run the test harness\n",
    "print(\"Task 2 Adam performance: \")\n",
    "\n",
    "run_test_harness_load_2task_adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 AdamW performance: \n",
      "> 79.880\n"
     ]
    }
   ],
   "source": [
    "# AdamW\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def define_model_2task(optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same',\n",
    "                     input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(lr=0.001, momentum=0.9)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = keras.optimizers.Adam()\n",
    "    elif optimizer == 'AdamW':\n",
    "        opt = tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)\t\t\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "\n",
    "def run_test_harness_2task_adam2():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_2task('AdamW')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_2task_adamW.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_2task_adam2()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_2task_adamW():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_2task_adamW.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# entry point, run the test harness\n",
    "print(\"Task 2 AdamW performance: \")\n",
    "run_test_harness_load_2task_adamW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.layers import Activation\n",
    "\n",
    "# task 4 Check if changing the order to Batch Norm then Dropout has an effect on performance.\n",
    "# Also check if the Dropout and Batch Norm are complementary ie having both Dropout and Batch Norm in the network\n",
    "# is better or worse than having a network that just has one of these regularization techniques.\n",
    "def define_model_4(optimizer='SGD', order='BD', use_both=True):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    if use_both or order == 'BD':\n",
    "        model.add(BatchNormalization())\n",
    "    if use_both or order == 'DB':\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same'))\n",
    "    if use_both or order == 'BD':\n",
    "        model.add(BatchNormalization())\n",
    "    if use_both or order == 'DB':\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same'))\n",
    "    if use_both or order == 'BD':\n",
    "        model.add(BatchNormalization())\n",
    "    if use_both or order == 'DB':\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(lr=0.001, momentum=0.9)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm then Dropout:\n",
      "> 82.720\n",
      "Dropout then BatchNorm:\n",
      "> 82.150\n"
     ]
    }
   ],
   "source": [
    "def run_test_harness_4BD():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_4(optimizer='Adam', order='BD', use_both=True)\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_task4BD.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_4BD()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_4_BD():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_task4BD.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "\n",
    "print(\"BatchNorm then Dropout:\")\n",
    "run_test_harness_load_4_BD()\n",
    "\n",
    "def run_test_harness_4_DB():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_4(optimizer='Adam', order='BD', use_both=True)\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_task4_DB.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_4_DB()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_4_DB():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_task4_DB.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "print(\"Dropout then BatchNorm:\")\n",
    "run_test_harness_load_4_DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_harness_4_B_only():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_4(optimizer='Adam', order='BD', use_both=True)\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_task4_B_only.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_4_B_only()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_4_B_only():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_task4_B_only.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only BatchNorm:\n",
      "> 82.020\n",
      "Only Dropout:\n",
      "> 81.880\n"
     ]
    }
   ],
   "source": [
    "print(\"Only BatchNorm:\")\n",
    "run_test_harness_load_4_B_only()\n",
    "\n",
    "\n",
    "def run_test_harness_4_D_only():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_4(optimizer='Adam', order='BD', use_both=True)\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_task4_D_only.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_4_D_only()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_4_D_only():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_task4_D_only.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Only Dropout:\")\n",
    "run_test_harness_load_4_D_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model):\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> Test Accuracy: %.3f' % (acc * 100.0))\n",
    "\n",
    "    #loss = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> Test Loss: %.3f' % _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.plot(history.history['accuracy'])\\nplt.plot(history.history['val_accuracy'])\\nplt.title('Model accuracy')\\nplt.ylabel('Accuracy')\\nplt.xlabel('Epoch')\\nplt.legend(['Train', 'Test'], loc='upper left')\\nplt.show()\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.experimental import CosineDecay\n",
    "from tqdm.keras import TqdmCallback\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# learning rate warm-up + cosine annealing\n",
    "\n",
    "model = load_model('final_model_task4BD.h5')\n",
    "\n",
    "INIT_LR = 5e-3  # initial learning rate\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "WARMUP_EPOCHS = 5  # number of epochs for warmup\n",
    "\n",
    "# load dataset\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "# prepare pixel data\n",
    "trainX, testX = prep_pixels_2(trainX, testX)\n",
    "\n",
    "# define the learning rate schedule\n",
    "cosine_decay = CosineDecay(INIT_LR, decay_steps=EPOCHS - WARMUP_EPOCHS)\n",
    "warmup_lr = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.0,  # start from zero\n",
    "    end_learning_rate=INIT_LR,  # ramp up to INIT_LR\n",
    "    decay_steps=WARMUP_EPOCHS\n",
    ")\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < WARMUP_EPOCHS:\n",
    "        return warmup_lr(epoch)\n",
    "    else:\n",
    "        return cosine_decay(epoch - WARMUP_EPOCHS)\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # we train 10-way classification\n",
    "    optimizer=Adamax(),  # learning rate will be set by `lr_scheduler`\n",
    "    metrics=['accuracy']  # report accuracy during training\n",
    ")\n",
    "\n",
    "# callback for printing of actual learning rate used by optimizer\n",
    "class LrHistory(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        print(\"Learning rate:\", K.get_value(model.optimizer.lr))\n",
    "\n",
    "# fit model\n",
    "#history = model.fit(\n",
    "#    trainX, trainY,  # prepared data\n",
    "#    batch_size=BATCH_SIZE,\n",
    "#    epochs=EPOCHS,\n",
    "#    callbacks=[LrHistory(), TqdmCallback(verbose=1)],\n",
    "#    validation_data=(testX, testY),\n",
    "#    shuffle=True,\n",
    "#    verbose=0\n",
    "#)\n",
    "\n",
    "\"\"\"plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## C Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try more extensive data-augmentations (more geometric data-augmentations: affine transformations, scaling and \n",
    "# rotation and/or photo-metric augmentations.) and see if this gives a performance boost.\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "# define the data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # randomly rotate images in the range (0-20 degrees)\n",
    "    zoom_range=0.15,  # Randomly zoom image \n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images horizontally\n",
    "    brightness_range=[0.2,1.0]  # change brightness of images\n",
    "    )\n",
    "\n",
    "# fit parameters from data\n",
    "datagen.fit(trainX)\n",
    "\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(trainX, trainY, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(32, 32, 3), cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_C1 = model.fit(\n",
    "    datagen.flow(trainX, trainY, batch_size=64),\n",
    "    epochs=30,\n",
    "    callbacks=[TqdmCallback(verbose=1)],\n",
    "    validation_data=(testX, testY),\n",
    "    shuffle=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "plt.plot(history_C1.history['accuracy'])\n",
    "plt.plot(history_C1.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Add, GlobalAveragePooling2D, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "def define_resnet_like_model():\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "\n",
    "    # Initial conv block\n",
    "    x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform')(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # First residual block\n",
    "    skip = x\n",
    "    x = Conv2D(32, (3, 3), padding='same', strides=(2, 2), activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    skip = Conv2D(32, (1, 1), padding='same', strides=(2, 2))(skip)\n",
    "    x = Add()([x, skip])  # Skip connection\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Additional residual blocks should go here...\n",
    "\n",
    "    # Global average pooling and output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_harness_resnet():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_resnet_like_model()\n",
    "    # fit model\n",
    "    history_C_resnet = model.fit(trainX, trainY, epochs=30, batch_size=64,validation_data=(testX, testY), verbose=2)\n",
    "    # save model\n",
    "    model.save('model_resnet.h5')\n",
    "    \n",
    "    plt.plot(history_C_resnet.history['accuracy'])\n",
    "    plt.plot(history_C_resnet.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_resnet():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('model_resnet.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/782 - 10s - loss: 1.7570 - accuracy: 0.3496 - val_loss: 1.5359 - val_accuracy: 0.4322 - 10s/epoch - 13ms/step\n",
      "Epoch 2/30\n",
      "782/782 - 9s - loss: 1.4460 - accuracy: 0.4730 - val_loss: 1.3633 - val_accuracy: 0.5073 - 9s/epoch - 11ms/step\n",
      "Epoch 3/30\n",
      "782/782 - 9s - loss: 1.3169 - accuracy: 0.5278 - val_loss: 1.3143 - val_accuracy: 0.5223 - 9s/epoch - 11ms/step\n",
      "Epoch 4/30\n",
      "782/782 - 9s - loss: 1.2452 - accuracy: 0.5543 - val_loss: 1.2297 - val_accuracy: 0.5547 - 9s/epoch - 11ms/step\n",
      "Epoch 5/30\n",
      "782/782 - 9s - loss: 1.1916 - accuracy: 0.5743 - val_loss: 1.1900 - val_accuracy: 0.5735 - 9s/epoch - 11ms/step\n",
      "Epoch 6/30\n",
      "782/782 - 9s - loss: 1.1489 - accuracy: 0.5892 - val_loss: 1.1471 - val_accuracy: 0.5851 - 9s/epoch - 11ms/step\n",
      "Epoch 7/30\n",
      "782/782 - 9s - loss: 1.1161 - accuracy: 0.6023 - val_loss: 1.1487 - val_accuracy: 0.5871 - 9s/epoch - 11ms/step\n",
      "Epoch 8/30\n",
      "782/782 - 9s - loss: 1.0873 - accuracy: 0.6143 - val_loss: 1.1254 - val_accuracy: 0.5930 - 9s/epoch - 11ms/step\n",
      "Epoch 9/30\n",
      "782/782 - 9s - loss: 1.0634 - accuracy: 0.6211 - val_loss: 1.0604 - val_accuracy: 0.6189 - 9s/epoch - 11ms/step\n",
      "Epoch 10/30\n",
      "782/782 - 9s - loss: 1.0397 - accuracy: 0.6309 - val_loss: 1.1032 - val_accuracy: 0.6059 - 9s/epoch - 11ms/step\n",
      "Epoch 11/30\n",
      "782/782 - 9s - loss: 1.0253 - accuracy: 0.6365 - val_loss: 1.0509 - val_accuracy: 0.6251 - 9s/epoch - 11ms/step\n",
      "Epoch 12/30\n",
      "782/782 - 9s - loss: 1.0044 - accuracy: 0.6443 - val_loss: 1.0653 - val_accuracy: 0.6237 - 9s/epoch - 11ms/step\n",
      "Epoch 13/30\n",
      "782/782 - 9s - loss: 0.9873 - accuracy: 0.6520 - val_loss: 1.0647 - val_accuracy: 0.6278 - 9s/epoch - 11ms/step\n",
      "Epoch 14/30\n",
      "782/782 - 9s - loss: 0.9711 - accuracy: 0.6559 - val_loss: 0.9931 - val_accuracy: 0.6502 - 9s/epoch - 11ms/step\n",
      "Epoch 15/30\n",
      "782/782 - 9s - loss: 0.9567 - accuracy: 0.6626 - val_loss: 1.0071 - val_accuracy: 0.6457 - 9s/epoch - 11ms/step\n",
      "Epoch 16/30\n",
      "782/782 - 9s - loss: 0.9442 - accuracy: 0.6666 - val_loss: 1.0146 - val_accuracy: 0.6378 - 9s/epoch - 11ms/step\n",
      "Epoch 17/30\n",
      "782/782 - 9s - loss: 0.9324 - accuracy: 0.6722 - val_loss: 0.9646 - val_accuracy: 0.6588 - 9s/epoch - 11ms/step\n",
      "Epoch 18/30\n",
      "782/782 - 9s - loss: 0.9225 - accuracy: 0.6732 - val_loss: 0.9715 - val_accuracy: 0.6539 - 9s/epoch - 11ms/step\n",
      "Epoch 19/30\n",
      "782/782 - 9s - loss: 0.9095 - accuracy: 0.6795 - val_loss: 0.9513 - val_accuracy: 0.6612 - 9s/epoch - 11ms/step\n",
      "Epoch 20/30\n",
      "782/782 - 9s - loss: 0.9021 - accuracy: 0.6810 - val_loss: 0.9619 - val_accuracy: 0.6640 - 9s/epoch - 11ms/step\n",
      "Epoch 21/30\n",
      "782/782 - 9s - loss: 0.8882 - accuracy: 0.6890 - val_loss: 0.9386 - val_accuracy: 0.6694 - 9s/epoch - 11ms/step\n",
      "Epoch 22/30\n",
      "782/782 - 9s - loss: 0.8792 - accuracy: 0.6902 - val_loss: 0.9297 - val_accuracy: 0.6758 - 9s/epoch - 11ms/step\n",
      "Epoch 23/30\n",
      "782/782 - 9s - loss: 0.8702 - accuracy: 0.6924 - val_loss: 0.9514 - val_accuracy: 0.6663 - 9s/epoch - 11ms/step\n",
      "Epoch 24/30\n",
      "782/782 - 9s - loss: 0.8587 - accuracy: 0.6962 - val_loss: 0.9552 - val_accuracy: 0.6626 - 9s/epoch - 11ms/step\n",
      "Epoch 25/30\n",
      "782/782 - 9s - loss: 0.8557 - accuracy: 0.6982 - val_loss: 0.9216 - val_accuracy: 0.6726 - 9s/epoch - 11ms/step\n",
      "Epoch 26/30\n",
      "782/782 - 9s - loss: 0.8446 - accuracy: 0.7027 - val_loss: 0.9281 - val_accuracy: 0.6688 - 9s/epoch - 11ms/step\n",
      "Epoch 27/30\n",
      "782/782 - 9s - loss: 0.8411 - accuracy: 0.7037 - val_loss: 0.9123 - val_accuracy: 0.6756 - 9s/epoch - 11ms/step\n",
      "Epoch 28/30\n",
      "782/782 - 9s - loss: 0.8302 - accuracy: 0.7076 - val_loss: 0.9164 - val_accuracy: 0.6741 - 9s/epoch - 11ms/step\n",
      "Epoch 29/30\n",
      "782/782 - 9s - loss: 0.8207 - accuracy: 0.7099 - val_loss: 0.9375 - val_accuracy: 0.6688 - 9s/epoch - 11ms/step\n",
      "Epoch 30/30\n",
      "782/782 - 9s - loss: 0.8171 - accuracy: 0.7118 - val_loss: 0.9252 - val_accuracy: 0.6770 - 9s/epoch - 11ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_test_harness_resnet()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 71.140\n"
     ]
    }
   ],
   "source": [
    "run_test_harness_load_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def define_model_noisy(optimizer='SGD', order='BD', use_both=True):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    if use_both or order == 'BD':\n",
    "        model.add(BatchNormalization())\n",
    "    if use_both or order == 'DB':\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same'))\n",
    "    if use_both or order == 'BD':\n",
    "        model.add(BatchNormalization())\n",
    "    if use_both or order == 'DB':\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same'))\n",
    "    if use_both or order == 'BD':\n",
    "        model.add(BatchNormalization())\n",
    "    if use_both or order == 'DB':\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(lr=0.001, momentum=0.9)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer='adam', loss=HuberLoss(delta=1.0), metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "class HuberLoss(Loss):\n",
    "    def __init__(self, delta=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.delta = delta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= self.delta\n",
    "        small_error_loss = tf.square(error) / 2\n",
    "        big_error_loss = self.delta * (tf.abs(error) - 0.5 * self.delta)\n",
    "        return tf.where(is_small_error, small_error_loss, big_error_loss)\n",
    "\n",
    "\n",
    "def add_noise_to_labels(y, noise_level):\n",
    "    num_noisy_labels = int(noise_level * y.shape[0])\n",
    "    noisy_indices = np.random.choice(y.shape[0], num_noisy_labels, replace=False)\n",
    "\n",
    "    y_noisy = y.copy()\n",
    "    for idx in noisy_indices:\n",
    "        # Create a random one-hot encoded label\n",
    "        random_label = np.zeros_like(y[idx])\n",
    "        random_class = np.random.randint(0, y.shape[1])  # Assuming y.shape[1] gives the number of classes\n",
    "        random_label[random_class] = 1\n",
    "\n",
    "        y_noisy[idx] = random_label\n",
    "\n",
    "    return y_noisy\n",
    "\n",
    "\n",
    "\n",
    "def run_test_harness_noisy():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # Add noise\n",
    "    noise_level = 0.2  # This means 20% of the labels will be noisy\n",
    "    trainY_noisy = add_noise_to_labels(trainY, noise_level)\n",
    "    # define model --- this model has had the best performance so far.\n",
    "    model = define_model_noisy(optimizer='Adam', order='BD', use_both=True)\n",
    "    # fit model\n",
    "    history_noisy = model.fit(trainX, trainY_noisy, epochs=30, batch_size=32, validation_data=(testX, testY))\n",
    "    # save model\n",
    "    model.save('model_noisy.h5')\n",
    "    \n",
    "    plt.plot(history_noisy.history['accuracy'])\n",
    "    plt.plot(history_noisy.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def run_test_harness_load_noisy():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # Add noise\n",
    "    noise_level = 0.2  # This means 20% of the labels will be noisy\n",
    "    trainY_noisy = add_noise_to_labels(trainY, noise_level)\n",
    "    # load model\n",
    "    model = load_model('model_noisy.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_models(n_models):\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # Add noise\n",
    "    noise_level = 0.2  # This means 20% of the labels will be noisy\n",
    "    trainY_noisy = add_noise_to_labels(trainY, noise_level)\n",
    "    models = []\n",
    "    for _ in tqdm(range(n_models)):\n",
    "        model = define_model_noisy()\n",
    "        # train the model\n",
    "        model.fit(trainX, trainY_noisy, epochs=10, batch_size=32)\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def predict_with_ensemble(models, X):\n",
    "    # make predictions\n",
    "    preds = [model.predict(X) for model in models]\n",
    "\n",
    "    # ensemble predictions\n",
    "    preds = np.array(preds)\n",
    "    ensemble_preds = np.argmax(np.mean(preds, axis=0), axis=1)\n",
    "    \n",
    "    return ensemble_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    # make ensemble predictions\n",
    "    ensemble_preds = predict_with_ensemble(models, X_test)\n",
    "\n",
    "    # calculate true labels\n",
    "    true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # calculate scores\n",
    "    accuracy = accuracy_score(true_labels, ensemble_preds)\n",
    "    precision = precision_score(true_labels, ensemble_preds, average='weighted')\n",
    "    recall = recall_score(true_labels, ensemble_preds, average='weighted')\n",
    "    f1 = f1_score(true_labels, ensemble_preds, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 17:45:27.033816: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_11/dropout_33/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 15s 8ms/step - loss: 0.0382 - accuracy: 0.3812\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0321 - accuracy: 0.5233\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0297 - accuracy: 0.5745\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0281 - accuracy: 0.6085\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0268 - accuracy: 0.6320\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0258 - accuracy: 0.6494\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0250 - accuracy: 0.6654\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0242 - accuracy: 0.6791\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0235 - accuracy: 0.6889\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0229 - accuracy: 0.6980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:03<08:13, 123.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 17:47:30.428072: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_12/dropout_36/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 15s 7ms/step - loss: 0.0384 - accuracy: 0.3775\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0326 - accuracy: 0.5118\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0301 - accuracy: 0.5661\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0284 - accuracy: 0.5999\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0271 - accuracy: 0.6247\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0262 - accuracy: 0.6425\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0253 - accuracy: 0.6587\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0246 - accuracy: 0.6714\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0239 - accuracy: 0.6831\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0233 - accuracy: 0.6919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [04:05<06:07, 122.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 17:49:32.478079: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_13/dropout_39/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 15s 7ms/step - loss: 0.0391 - accuracy: 0.3626\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0330 - accuracy: 0.5054\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0304 - accuracy: 0.5578\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0287 - accuracy: 0.5932\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0275 - accuracy: 0.6177\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0266 - accuracy: 0.6356\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0257 - accuracy: 0.6506\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0250 - accuracy: 0.6630\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0242 - accuracy: 0.6761\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0236 - accuracy: 0.6852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [06:08<04:06, 123.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 17:51:36.317507: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_14/dropout_42/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 15s 8ms/step - loss: 0.0384 - accuracy: 0.3785\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0325 - accuracy: 0.5148\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0300 - accuracy: 0.5697\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0284 - accuracy: 0.6014\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0272 - accuracy: 0.6252\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0262 - accuracy: 0.6431\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0253 - accuracy: 0.6608\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0245 - accuracy: 0.6715\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0238 - accuracy: 0.6838\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0232 - accuracy: 0.6955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [08:12<02:03, 123.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 17:53:39.831029: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_15/dropout_45/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 15s 8ms/step - loss: 0.0389 - accuracy: 0.3626\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0327 - accuracy: 0.5107\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0301 - accuracy: 0.5643\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0285 - accuracy: 0.5998\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0272 - accuracy: 0.6229\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0262 - accuracy: 0.6407\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0253 - accuracy: 0.6590\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0245 - accuracy: 0.6727\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0239 - accuracy: 0.6820\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0232 - accuracy: 0.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [10:37<00:00, 127.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Accuracy: 0.8311, Precision: 0.8330268639948474, Recall: 0.8311, F1: 0.8314742029490115\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "# prepare pixel data\n",
    "trainX, testX = prep_pixels_2(trainX, testX)\n",
    "\n",
    "models = train_models(5)\n",
    "evaluate_models(models, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_test_harness_noisy()\n",
    "\n",
    "evaluate_models(models, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming you have binary classification and you're using binary cross-entropy loss\n",
    "def bootstrap_binary_crossentropy(y_true, y_pred):\n",
    "    bootstrap_target = 0.95 # the target probability for positive samples\n",
    "    bootstrap_weight = 0.95 # the weight for positive samples, 1 - this weight will be used for negative samples\n",
    "    \n",
    "    # calculate binary cross-entropy as usual\n",
    "    bce = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # calculate bootstrap target and weight based on true labels\n",
    "    bootstrap_target_tensor = y_true * bootstrap_target + (1 - y_true) * (1 - bootstrap_target)\n",
    "    bootstrap_weight_tensor = y_true * bootstrap_weight + (1 - y_true) * (1 - bootstrap_weight)\n",
    "    \n",
    "    # apply bootstrap weighting\n",
    "    bootstrap_bce = bootstrap_weight_tensor * keras.losses.binary_crossentropy(bootstrap_target_tensor, y_pred)\n",
    "    \n",
    "    return bootstrap_bce\n",
    "\n",
    "model.compile(loss=bootstrap_binary_crossentropy, optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 73.480\n"
     ]
    }
   ],
   "source": [
    "# test harness for evaluating models on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig('base_line_plot.png')\n",
    "    pyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    history = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 17:20:35.105936: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_25/dropout_31/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 82.860\n"
     ]
    }
   ],
   "source": [
    "# baseline model with dropout on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig('baseline_dropout_plot.png')\n",
    "    pyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    history = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 71.410\n"
     ]
    }
   ],
   "source": [
    "# baseline model with weight decay on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig('Baseline_weight_decay.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:80: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 83.700\n"
     ]
    }
   ],
   "source": [
    "# baseline model with data augmentation on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig('baseline_data_aug_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\t# prepare iterator\n",
    "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "\t# fit model\n",
    "\tsteps = int(trainX.shape[0] / 64)\n",
    "\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=100, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
