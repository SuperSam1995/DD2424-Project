{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 17:26:46.201086: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-18 17:26:47.090348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-18 17:26:47.090463: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-18 17:26:47.090474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# save the final model to file\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point, run the test harness\n",
    "#run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 17:26:48.907510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:26:48.918797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:26:48.920448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:26:48.922592: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-18 17:26:48.923459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:26:48.925134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:26:48.926717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:26:49.679245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:26:49.680867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:26:49.682215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:26:49.683539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13143 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2023-05-18 17:26:51.064448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 72.990\n"
     ]
    }
   ],
   "source": [
    "# evaluate the deep model on the test dataset\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness_load():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 performance: \n",
      "> 74.840\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# See if normalizing the data to have zero mean and standard deviation 1 improves performance\n",
    "\n",
    "def prep_pixels_2(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # calculate mean and standard deviation\n",
    "    train_mean, train_std = train_norm.mean(), train_norm.std()\n",
    "    test_mean, test_std = test_norm.mean(), test_norm.std()\n",
    "    # global standardization of pixels\n",
    "    train_norm = (train_norm - train_mean) / train_std\n",
    "    test_norm = (test_norm - test_mean) / test_std\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness_1task():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_1task.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_1task()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def run_test_harness_load_1task():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_1task.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# entry point, run the test harness\n",
    "print(\"Task 1 performance: \")\n",
    "run_test_harness_load_1task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 Adam performance: \n",
      "> 75.900\n"
     ]
    }
   ],
   "source": [
    "## task 2, Replace the SGD + momentum optimizer with Adam and then AdamW. Do these optimizers lead to better performance and/or faster convergence?\n",
    "import keras.optimizers\n",
    "\n",
    "\n",
    "def define_model_2task(optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(lr=0.001, momentum=0.9)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "\n",
    "def run_test_harness_2task_adam():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_2task('Adam')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_2task_adam.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_2task_adam()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "\n",
    "def run_test_harness_load_2task_adam():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_2task_adam.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# entry point, run the test harness\n",
    "print(\"Task 2 Adam performance: \")\n",
    "\n",
    "run_test_harness_load_2task_adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 AdamW performance: \n",
      "> 79.880\n"
     ]
    }
   ],
   "source": [
    "# AdamW\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def define_model_2task(optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same',\n",
    "                     input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(lr=0.001, momentum=0.9)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = keras.optimizers.Adam()\n",
    "    elif optimizer == 'AdamW':\n",
    "        opt = tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)\t\t\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "\n",
    "def run_test_harness_2task_adam2():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_2task('AdamW')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_2task_adamW.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_2task_adam2()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_2task_adamW():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_2task_adamW.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# entry point, run the test harness\n",
    "print(\"Task 2 AdamW performance: \")\n",
    "run_test_harness_load_2task_adamW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.layers import Activation\n",
    "\n",
    "# task 4 Check if changing the order to Batch Norm then Dropout has an effect on performance.\n",
    "# Also check if the Dropout and Batch Norm are complementary ie having both Dropout and Batch Norm in the network\n",
    "# is better or worse than having a network that just has one of these regularization techniques.\n",
    "def define_model_4(optimizer='SGD', order='BD', use_both=True):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    if use_both or order == 'BD':\n",
    "        model.add(BatchNormalization())\n",
    "    if use_both or order == 'DB':\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same'))\n",
    "    if use_both or order == 'BD':\n",
    "        model.add(BatchNormalization())\n",
    "    if use_both or order == 'DB':\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same'))\n",
    "    if use_both or order == 'BD':\n",
    "        model.add(BatchNormalization())\n",
    "    if use_both or order == 'DB':\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(lr=0.001, momentum=0.9)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm then Dropout:\n",
      "> 82.720\n",
      "Dropout then BatchNorm:\n",
      "> 82.150\n"
     ]
    }
   ],
   "source": [
    "def run_test_harness_4BD():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_4(optimizer='Adam', order='BD', use_both=True)\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_task4BD.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_4BD()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_4_BD():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_task4BD.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "\n",
    "print(\"BatchNorm then Dropout:\")\n",
    "run_test_harness_load_4_BD()\n",
    "\n",
    "def run_test_harness_4_DB():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_4(optimizer='Adam', order='BD', use_both=True)\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_task4_DB.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_4_DB()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_4_DB():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_task4_DB.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "print(\"Dropout then BatchNorm:\")\n",
    "run_test_harness_load_4_DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_harness_4_B_only():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_4(optimizer='Adam', order='BD', use_both=True)\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_task4_B_only.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_4_B_only()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_4_B_only():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_task4_B_only.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only BatchNorm:\n",
      "> 82.020\n",
      "Only Dropout:\n",
      "> 81.880\n"
     ]
    }
   ],
   "source": [
    "print(\"Only BatchNorm:\")\n",
    "run_test_harness_load_4_B_only()\n",
    "\n",
    "\n",
    "def run_test_harness_4_D_only():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model_4(optimizer='Adam', order='BD', use_both=True)\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model_task4_D_only.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_4_D_only()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_4_D_only():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('final_model_task4_D_only.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Only Dropout:\")\n",
    "run_test_harness_load_4_D_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model):\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> Test Accuracy: %.3f' % (acc * 100.0))\n",
    "\n",
    "    #loss = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> Test Loss: %.3f' % _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb0f17df3f9434c86002ab27b10869e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 17:27:20.443257: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_8/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-05-18 17:27:20.695829: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x55ca0534f250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-18 17:27:20.695874: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-05-18 17:27:20.702882: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-18 17:27:20.850893: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n",
      "Learning rate: 0.001\n",
      "Learning rate: 0.001\n",
      "Learning rate: 0.001\n",
      "Learning rate: 0.001\n",
      "Learning rate: 0.001\n",
      "Learning rate: 0.001\n",
      "Learning rate: 0.001\n",
      "Learning rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce9758a190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.experimental import CosineDecay\n",
    "from tqdm.keras import TqdmCallback\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# learning rate warm-up + cosine annealing\n",
    "\n",
    "model = load_model('final_model_task4BD.h5')\n",
    "\n",
    "INIT_LR = 5e-3  # initial learning rate\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "WARMUP_EPOCHS = 5  # number of epochs for warmup\n",
    "\n",
    "# load dataset\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "# prepare pixel data\n",
    "trainX, testX = prep_pixels_2(trainX, testX)\n",
    "\n",
    "# define the learning rate schedule\n",
    "cosine_decay = CosineDecay(INIT_LR, decay_steps=EPOCHS - WARMUP_EPOCHS)\n",
    "warmup_lr = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.0,  # start from zero\n",
    "    end_learning_rate=INIT_LR,  # ramp up to INIT_LR\n",
    "    decay_steps=WARMUP_EPOCHS\n",
    ")\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < WARMUP_EPOCHS:\n",
    "        return warmup_lr(epoch)\n",
    "    else:\n",
    "        return cosine_decay(epoch - WARMUP_EPOCHS)\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # we train 10-way classification\n",
    "    optimizer=Adamax(),  # learning rate will be set by `lr_scheduler`\n",
    "    metrics=['accuracy']  # report accuracy during training\n",
    ")\n",
    "\n",
    "# callback for printing of actual learning rate used by optimizer\n",
    "class LrHistory(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        print(\"Learning rate:\", K.get_value(model.optimizer.lr))\n",
    "\n",
    "# fit model\n",
    "model.fit(\n",
    "    trainX, trainY,  # prepared data\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[LrHistory(), TqdmCallback(verbose=1)],\n",
    "    validation_data=(testX, testY),\n",
    "    shuffle=True,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## C Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try more extensive data-augmentations (more geometric data-augmentations: affine transformations, scaling and \n",
    "# rotation and/or photo-metric augmentations.) and see if this gives a performance boost.\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "# define the data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # randomly rotate images in the range (0-20 degrees)\n",
    "    zoom_range=0.15,  # Randomly zoom image \n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images horizontally\n",
    "    brightness_range=[0.2,1.0]  # change brightness of images\n",
    "    )\n",
    "\n",
    "# fit parameters from data\n",
    "datagen.fit(trainX)\n",
    "\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(trainX, trainY, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(32, 32, 3), cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88f4e3794c3449eae4f192dcc8e5778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 17:29:24.867836: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_8/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce96f266d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    datagen.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[TqdmCallback(verbose=1)],\n",
    "    validation_data=(testX, testY),\n",
    "    shuffle=True,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Add, GlobalAveragePooling2D, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "def define_resnet_like_model():\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "\n",
    "    # Initial conv block\n",
    "    x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform')(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # First residual block\n",
    "    skip = x\n",
    "    x = Conv2D(32, (3, 3), padding='same', strides=(2, 2), activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    skip = Conv2D(32, (1, 1), padding='same', strides=(2, 2))(skip)\n",
    "    x = Add()([x, skip])  # Skip connection\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Additional residual blocks should go here...\n",
    "\n",
    "    # Global average pooling and output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_harness_resnet():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # define model\n",
    "    model = define_resnet_like_model()\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)\n",
    "    # save model\n",
    "    model.save('model_resnet.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness_4BD()\n",
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "\n",
    "def run_test_harness_load_resnet():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_2(trainX, testX)\n",
    "    # load model\n",
    "    model = load_model('model_resnet.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test_harness_resnet()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 71.140\n"
     ]
    }
   ],
   "source": [
    "run_test_harness_load_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
